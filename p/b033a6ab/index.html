<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>HDFS分布式文件系统的伪分布式搭建 | siworae</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">HDFS分布式文件系统的伪分布式搭建</h1><a id="logo" href="/.">siworae</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">HDFS分布式文件系统的伪分布式搭建</h1><div class="post-meta"><a href="/p/b033a6ab/#comments" class="comment-count"></a><p><span class="date">Jan 29, 2019</span><span><a href="/categories/HADOOP/" class="category">HADOOP</a><a href="/categories/HADOOP/HDFS/" class="category">HDFS</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span><span>字数统计:<span class="post-count">2.1k</span>字 </span><span>阅读时长≈<span class="post-count">7</span>分钟</span></p></div><div class="post-content"><h1 id="分布式文件存储系统HDFS"><a href="#分布式文件存储系统HDFS" class="headerlink" title="分布式文件存储系统HDFS"></a>分布式文件存储系统HDFS</h1><h2 id="1、什么是HDFS"><a href="#1、什么是HDFS" class="headerlink" title="1、什么是HDFS"></a>1、什么是HDFS</h2><p>HDFS是Hadoop分布式文件存储系统,主要用来解决海量数据的存储问题.</p>
<p>HDFS具有高容错性,存入的数据会自动保存多个副本,在副本丢失的情况下会自动恢复副本;同时在大数据批处理的情况下也能将数据位置暴露给计算框架,移动计算而非移动数据,但是HDFS也有一些缺点,比如说只能支持到秒级别的响应,暂时还不能支持到毫秒级别的响应,小文件存储时占用内容过高的问题.</p>
<h2 id="2、HDFS功能模块"><a href="#2、HDFS功能模块" class="headerlink" title="2、HDFS功能模块"></a>2、HDFS功能模块</h2><h3 id="2-1、HDSF架构图"><a href="#2-1、HDSF架构图" class="headerlink" title="2.1、HDSF架构图"></a>2.1、HDSF架构图</h3><img src="/p/b033a6ab/1.jpg" title="图片上传失败">
<h3 id="2-2、功能模块"><a href="#2-2、功能模块" class="headerlink" title="2.2、功能模块"></a>2.2、功能模块</h3><h4 id="2-2-1、HDFS数据存储单元-block"><a href="#2-2-1、HDFS数据存储单元-block" class="headerlink" title="2.2.1、HDFS数据存储单元(block)"></a>2.2.1、HDFS数据存储单元(block)</h4><p>所有上传至HDFS的文件都会被自动切分成固定大小的数据块(block),</p>
<p>在2.x的版本中,默认的大小为128MB,且可自定义配置大小,在1.x的版本中默认的大小为64MB,</p>
<p>若文件大小不足于128MB时也会单独打包成一个block,</p>
<p>每个被切分的block块都会被存储在不同的节点上,每个block默认存在三个副本,并且这个三个副本会被存储在不同的节点上,</p>
<p>Block大小和副本数通过Client端上传文件时设置，文件上传成功后副本数可以变更，Block Size不可变更,</p>
<p>HDFS会自动的线性切分上传的文件,每个block块都会有一个偏移量(offset),用来记录文件切分的位置,HDFS可根据offset来将各个block块合并成完整的文件</p>
<p>block存储模拟图</p>
<img src="/p/b033a6ab/2.jpg" title="图片上传失败">
<h4 id="2-2-2、NameNode-NN"><a href="#2-2-2、NameNode-NN" class="headerlink" title="2.2.2、NameNode(NN)"></a>2.2.2、NameNode(NN)</h4><p>NameNode的主要功能是接受客户端的读/写服务,并且收集各个block利用心跳机制发送的block列表信息</p>
<p>NameNode是存在于内存中的,基于内存存储,不会和磁盘发送交互</p>
<p>NameNode保存了metadata的元数据信息,包括文件的owership(归属)和permissions(权限),文件的大小和创建时间,block列表和block的偏移量</p>
<p>NameNode的metadata数据也会进行持久化,metadata持久化之后保存到磁盘的文件名是<code>fsimage</code>,这个文件类似于系统的快照,保存着最新的元数据信息,在HDFS启动时,会将fsimage文件加载到内存中</p>
<p>每次客户端对文件进行了修改之后,editslog会保存客户端的操作记录,只有当客户端操作成功之后才会去更新metadata的信息,这就相当于<code>metadata = editslog + fsimage</code>,而,HDFS会将客户端的每次操作都记录到edits里面.</p>
<h4 id="2-2-3、DataNode-DN"><a href="#2-2-3、DataNode-DN" class="headerlink" title="2.2.3、DataNode(DN)"></a>2.2.3、DataNode(DN)</h4><p>DataNode是以文件的形式来存储数据(block) 的,并且保存着block的元信息文件,相当于是直接操作数据文件的角色,在DataNode启动的时候会向NameNode发送其节点的block信息,并且之后每3秒一次与NameNode保存心跳联系,如果NameNode十分钟没有收到DataNode的心跳信息,就会认为此DataNode节点挂了,会将存储在这个节点的block复制到其他DataNode节点上,维持其block的副本数量,这个就是HDFS的副本恢复策略.</p>
<h4 id="2-2-4、SecondaryNameNode-SNN"><a href="#2-2-4、SecondaryNameNode-SNN" class="headerlink" title="2.2.4、SecondaryNameNode(SNN)"></a>2.2.4、SecondaryNameNode(SNN)</h4><p>SNN的主要功能就是帮助NameNode去合并editslog和fsimage文件,以此减少NameNode的启动时间.</p>
<p>至于为什么说会减少NameNode的启动时间,是因为在HDFS系统启动的时候,SecondaryNameNode就已经将各个DataNode的editslog + fsimage文件合并为最新的metadata文件了,那么NameNode只需要直接读取这个metadata文件就可以了,而不用去合并读取每个DataNode的editslog + fsimage.</p>
<p>SNN的合并时间和机制</p>
<ol>
<li>根据配置文件设置的时间间隔fs.checkpoint.period 默认3600秒。</li>
<li>根据配置文件设置edits log大小 fs.checkpoint.size 规定edits文件的最大值默认是64MB</li>
</ol>
<p>SecondaryNameNode SNN合并流程</p>
<img src="/p/b033a6ab/3.jpg" title="图片上传失败">
<p>首先是NN中的Fsimage和edits文件通过网络拷贝，到达SNN服务器中，拷贝的同时，用户的实时在操作数据，那么NN中就会从新生成一个edits来记录用户的操作，而另一边的SＮＮ将拷贝过来的edits和fsimage进行合并，合并之后就替换NN中的fsimage。之后NN根据fsimage进行操作（当然每隔一段时间就进行替换合并，循环）。当然新的edits与合并之后传输过来的fsimage会在下一次时间内又进行合并</p>
<h4 id="2-2-5、HDFS读写流程"><a href="#2-2-5、HDFS读写流程" class="headerlink" title="2.2.5、HDFS读写流程"></a>2.2.5、HDFS读写流程</h4><p>HDFS写流程</p>
<img src="/p/b033a6ab/4.jpg" title="图片上传失败">
<p>1.Client调用create方法,通过distributedFileSystem实例去调用NameNode去预先创建一些空的没有关联的block块</p>
<p>2.Client通过FSDataOutputStream流写入数据</p>
<p>3.FSDataOutputStream会构建一个write packet管道流,数据包会构成一个datamq(数据队列),然后通过流的方式写入DataNode</p>
<p>4.DataNode成功写入block块之后,会根据副本存放策略去复制block块的副本存放到其他的DataNode节点上</p>
<p>5.当所有的block块副本写入成功之后,开始写入第二个block块</p>
<p>6.ack packet相当于是一个监管者的身份,它会留存一份datamq中的数据,同时还会监听DataNode的状态,当在写入的过程中DataNode宕机了或者其他无法写入的情况下,ack packet会通知FSDataOutputStream关闭当前管道流并在其他DataNode节点上开闭新的管道流,并将之前留存的数据发送到新的管道流的datamq中,重新将block块写入到新的DataNode节点中.如果写入过程中没有发生问题,那么ack packet会被直接丢弃</p>
<p>HDFS读流程</p>
<img src="/p/b033a6ab/5.jpg" title="图片上传失败">
<p>1.Client调用open方法,通过distributedFileSystem实例去读取NameNode的metadata元信息</p>
<p>2.NameNode返回一批block locations信息给客户端</p>
<p>3.Client获取到block的信息之后,通过FSDataInputStream去读取DataNode中的block文件(读取过程中会按照DataNode的拓扑网络结构图,就近原则去读取DataNode中的数据,当读到的block构成了一个完整的文件时,读取就结束了)</p>
<h2 id="3、Hadoop搭建"><a href="#3、Hadoop搭建" class="headerlink" title="3、Hadoop搭建"></a>3、Hadoop搭建</h2><h3 id="1、环境配置"><a href="#1、环境配置" class="headerlink" title="1、环境配置"></a>1、环境配置</h3><h4 id="1-1、jdk安装"><a href="#1-1、jdk安装" class="headerlink" title="1.1、jdk安装"></a>1.1、jdk安装</h4><p>jdk的具体安装步骤就不阐述了,网上很多教程,随便找找都有</p>
<h4 id="1-2、安装Hadoop"><a href="#1-2、安装Hadoop" class="headerlink" title="1.2、安装Hadoop"></a>1.2、安装Hadoop</h4><p>官网下载<a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener">Hadoop</a>压缩包</p>
<p>上传hadoop.tar.gz到服务器并解压至/usr/soft/目录下(此目录自行定义)</p>
<h4 id="1-3、配置环境变量"><a href="#1-3、配置环境变量" class="headerlink" title="1.3、配置环境变量"></a>1.3、配置环境变量</h4><p>配置root用户下的环境变量</p>
<p>HADOOP_HOME配的路径为你解压后的根目录</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /root/.bash_profile</span><br><span class="line"></span><br><span class="line"><span class="attribute">HADOOP_HOME</span>=//usr/soft/hadoop-2.6.5</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>
<h4 id="1-4、修改配置文件"><a href="#1-4、修改配置文件" class="headerlink" title="1.4、修改配置文件"></a>1.4、修改配置文件</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd <span class="regexp">/usr/</span>soft<span class="regexp">/hadoop-2.6.5/</span>etc<span class="regexp">/hadoop</span></span><br></pre></td></tr></table></figure>
<p>修改hadoop-env.sh</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br><span class="line"><span class="comment">## 配置的是你安装的jdk的根目录,也就是你的jdk的环境变量</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/soft/jdk1.8.0_191</span><br></pre></td></tr></table></figure>
<p>然后重新加载环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>修改core-site.xml</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>fs.defaultFS<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="meta">## 此处配置的是你的服务器的IP和端口</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>hdfs:<span class="comment">//192.168.230.220:9000&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>hadoop.tmp.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="meta">## 配置你的数据存放的路径</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/var/</span>hadoop/local<span class="params">&lt;/value&gt;</span></span><br><span class="line">     <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改hdfs-site.xml</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml </span><br><span class="line"></span><br><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line"><span class="params">&lt;property&gt;</span></span><br><span class="line">	 <span class="meta">## 配置block块的副本数量,默认为1</span></span><br><span class="line">      <span class="params">&lt;name&gt;</span>dfs.replication<span class="params">&lt;/name&gt;</span></span><br><span class="line">      <span class="params">&lt;value&gt;</span><span class="number">3</span><span class="params">&lt;/value&gt;</span></span><br><span class="line"> <span class="params">&lt;/property&gt;</span></span><br><span class="line"> <span class="params">&lt;property&gt;</span></span><br><span class="line"> 	<span class="meta">## 配置服务器的IP和nameNode的端口</span></span><br><span class="line">     <span class="params">&lt;name&gt;</span>dfs.namenode.secondary.http-address<span class="params">&lt;/name&gt;</span></span><br><span class="line">    <span class="params">&lt;value&gt;</span><span class="number">192.168</span><span class="number">.230</span><span class="number">.220</span>:<span class="number">50090</span><span class="params">&lt;/value&gt;</span></span><br><span class="line"> <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改 slaves(配置datanode节点)</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">vim slaves</span></span><br></pre></td></tr></table></figure>
<p>文件内直接添加服务器的节点IP,这里因为是用单机模拟分布式,所以只填写了192.168.230.220一个IP,正常分布式环境应该填写多个IP地址</p>
<p>格式化HDFS</p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -<span class="built_in">format</span></span><br></pre></td></tr></table></figure>
<p>启动</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">start</span>-dfs.sh</span><br></pre></td></tr></table></figure>
<p>查看HDFS进程是否启动</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">jps</span></span><br></pre></td></tr></table></figure>
<img src="/p/b033a6ab/6.jpg" title="图片上传失败">
<p>出现以上进程说明HDFS进程已经启动了,但是进程启动了并不代表HDFS系统已经启动了</p>
<p>你可以在浏览器访问<code>192.168.230.220:50070</code>HDFS的管理界面</p>
<img src="/p/b033a6ab/7.jpg" title="图片上传失败">
<p>你可以进入如上页面并且状态为active存活状态,则说明HDFS已经启动成功了</p>
<p>如果不能访问请关闭虚拟机的防火墙</p>
</div><div class="tags"><a href="/tags/HDFS/">HDFS</a></div><div class="post-share"></div><div class="post-nav"><a href="/p/fffa5954/" class="next">Nginx负载均衡的实现</a></div><div id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80MTk5OC8xODU0NQ=="></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#分布式文件存储系统HDFS"><span class="toc-text">分布式文件存储系统HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、什么是HDFS"><span class="toc-text">1、什么是HDFS</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、HDFS功能模块"><span class="toc-text">2、HDFS功能模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1、HDSF架构图"><span class="toc-text">2.1、HDSF架构图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2、功能模块"><span class="toc-text">2.2、功能模块</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1、HDFS数据存储单元-block"><span class="toc-text">2.2.1、HDFS数据存储单元(block)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2、NameNode-NN"><span class="toc-text">2.2.2、NameNode(NN)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3、DataNode-DN"><span class="toc-text">2.2.3、DataNode(DN)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-4、SecondaryNameNode-SNN"><span class="toc-text">2.2.4、SecondaryNameNode(SNN)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-5、HDFS读写流程"><span class="toc-text">2.2.5、HDFS读写流程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、Hadoop搭建"><span class="toc-text">3、Hadoop搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、环境配置"><span class="toc-text">1、环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1、jdk安装"><span class="toc-text">1.1、jdk安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2、安装Hadoop"><span class="toc-text">1.2、安装Hadoop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3、配置环境变量"><span class="toc-text">1.3、配置环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4、修改配置文件"><span class="toc-text">1.4、修改配置文件</span></a></li></ol></li></ol></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/p/b033a6ab/">HDFS分布式文件系统的伪分布式搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/p/fffa5954/">Nginx负载均衡的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/p/ee9f7bfc/">Spring集成RabbitMQ</a></li><li class="post-list-item"><a class="post-list-link" href="/p/64c322b1/">基于Netty的websocket简单实现</a></li><li class="post-list-item"><a class="post-list-link" href="/p/1e2cf77e/">WebSocket实现Java后台消息推送</a></li><li class="post-list-item"><a class="post-list-link" href="/p/1d70d5b2/">基于zookeeper的Dubbo框架搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/p/b5f3cf78/">在java环境中操作redis服务器</a></li><li class="post-list-item"><a class="post-list-link" href="/p/9227d01/">Linux下redis的读写分离配置和高可用环境配置</a></li><li class="post-list-item"><a class="post-list-link" href="/p/ae3b3943/">windows下的hexo+GitHub个人博客搭建</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HADOOP/">HADOOP</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/HADOOP/HDFS/">HDFS</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Java/Dubbo/">Dubbo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/Netty/">Netty</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/Nginx/">Nginx</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/redis/">redis</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/websocket/">websocket</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/RabbitMQ/">RabbitMQ</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/RabbitMQ/" style="font-size: 15px;">RabbitMQ</a> <a href="/tags/websocket/" style="font-size: 15px;">websocket</a> <a href="/tags/Dubbo/" style="font-size: 15px;">Dubbo</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><i class="fa fa-user"></i>本站总访问量:<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次 <i class="fa fa-user"></i>本站总访问数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人 <i class="fa fa-you"></i>博客全站共:<span class="post-count">18.4k</span>字</p><p><span> Copyright &copy;<a href="/." rel="nofollow">siworae.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>(function(d, s) {
  var j, e = d.getElementsByTagName('body')[0];
  if (typeof LivereTower === 'function') { return; }
  j = d.createElement(s);
  j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
  j.async = true;
  e.appendChild(j);
})(document, 'script');
</script><script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body></html>